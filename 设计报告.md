# 基于Sobel算子的Canny边缘检测算法在车牌识别中的应用案例研究

## 摘要

本技术报告研究了基于Sobel算子的Canny边缘检测算法在车牌识别中的应用。车牌识别是计算机视觉领域的重要应用之一，对于交通管理、车辆追踪和安防等领域具有广泛的实际意义。Canny边缘检测算法以其准确性和鲁棒性而备受关注，本报告将探索如何将Canny算法与Sobel算子相结合，实现车牌识别中的边缘检测。我们将主要介绍Canny边缘检测算法的原理和关键步骤，并详细描述实现过程。通过实验和案例研究，我们将评估算法在车牌识别中的性能和效果。

## 研究背景与动机

在计算机视觉和图像处理领域，边缘检测是一项重要的任务，它对于目标检测、图像分割、特征提取等应用起着关键作用。边缘是图像中物体和背景之间的边界，包含了重要的形状、纹理和结构信息。因此，准确地检测和提取图像中的边缘对于进一步的图像分析和处理至关重要。

然而，传统的边缘检测算法在面对一些挑战时表现不佳。这些挑战包括图像噪声、边缘模糊、边缘断裂和多重响应等问题。为了解决这些问题，研究人员一直在寻求更精确、鲁棒和可靠的边缘检测算法。

Canny边缘检测算法作为一种经典的边缘检测方法应运而生。它由John Canny于1986年提出，成为了一种被广泛应用的算法。Canny算法通过综合应用多个步骤来解决传统算法面临的问题，包括噪声滤波、梯度计算、非极大值抑制和双阈值处理等。

Canny边缘检测算法具有许多优点。首先，它能够提供准确的边缘检测结果，并能够抑制噪声和响应多个边缘的问题。其次，Canny算法的可调参数使其适用于各种图像和应用场景。此外，Canny算法在边缘连接和细化方面表现出良好的性能。

基于以上背景和动机，本研究旨在深入研究和实现Canny边缘检测算法，并将其应用于车牌识别这一具体案例中。车牌识别是计算机视觉中的重要应用之一，对于交通管理、车辆追踪和安防等领域具有广泛的实际意义。通过本研究，我们希望探索Canny算法在车牌识别中的潜力和效果，并为相关领域的研究和应用提供一种简单而有效的边缘检测解决方案。

## 研究问题与挑战

在研究Canny边缘检测算法应用于车牌识别的过程中，我们面临着一些研究问题和挑战，包括但不限于以下几个方面：

1. **复杂背景干扰问题：** 车牌通常位于复杂的背景中，例如车辆、道路和其他物体。这些背景元素可能会干扰车牌边缘的准确检测。因此，如何在复杂背景中准确地检测和提取车牌边缘是一个挑战。
2. **车牌变形和失真问题：** 由于车辆的角度、距离和光照等因素的影响，车牌可能会出现变形和失真。这会导致边缘形状的改变和断裂，增加了边缘检测的难度。因此，如何应对车牌的变形和失真问题是一个关键挑战。
3. **噪声和边缘模糊问题：** 在实际图像中，由于图像采集设备和环境等因素，车牌图像可能受到噪声和边缘模糊的影响。这些因素会降低边缘的清晰度和质量，对边缘检测的准确性造成影响。因此，如何在存在噪声和边缘模糊的情况下有效地检测车牌边缘是一个挑战。
4. **实时性要求：** 车牌识别通常需要在实时或近实时的场景中应用，例如交通监控和车辆识别。因此，对于Canny边缘检测算法的应用来说，如何在保证准确性的同时提高算法的处理速度，以满足实时性要求，是一个重要的研究问题。

通过面对这些研究问题和挑战，我们希望在实现Canny边缘检测算法并将其应用于车牌识别的过程中，寻求解决方案并提出相应的改进方法，以提高车牌边缘检测的准确性、鲁棒性和实时性。

## 国内外相关工作

在Canny边缘检测算法和车牌识别领域，已经有许多国内外的相关工作和研究。以下是一些相关工作的简要概述：

1. **Canny边缘检测算法改进：** 有许多研究针对Canny边缘检测算法进行改进和优化。例如，一些研究提出了基于局部自适应阈值的方法来改善边缘检测结果。还有一些研究关注于利用机器学习和深度学习技术来改进边缘检测的性能。
2. **车牌检测与识别算法：** 在车牌识别领域，研究人员提出了各种车牌检测和识别算法。这些算法包括基于颜色分割、形状分析和特征提取等方法。一些研究还利用机器学习和深度学习技术来实现车牌检测和识别的自动化。
3. **边缘连接和轮廓提取方法：** 除了Canny算法，还有一些其他的边缘连接和轮廓提取方法被用于车牌边缘检测。例如，基于连通性的方法和基于梯度的方法等。这些方法尝试通过边缘连接和轮廓提取来提高边缘检测的准确性和鲁棒性。
4. **深度学习在车牌识别中的应用：** 近年来，深度学习技术在车牌识别领域取得了显著的进展。研究人员利用深度神经网络和卷积神经网络来实现车牌的检测和识别。这些方法通过端到端的学习，提高了车牌识别的准确性和鲁棒性。

这些国内外的相关工作为我们的研究提供了宝贵的参考和借鉴。通过对这些工作的研究和分析，我们可以更好地了解Canny边缘检测算法在车牌识别中的优势和不足。

## Canny算法概要与详细设计

基于边缘检测的车牌识别最基础也是最重要的部分就是边缘检测。边缘检测的效果好坏直接影响了后续识别车牌的效果，包括速度和准确性。下面将详细介绍我们对Canny算法的设计与实现。

基于Sobel算子的Canny边缘检测算法的主要步骤包括以下几个方面：

1. **图像预处理：** 对输入的车牌图像进行预处理，包括去噪和图像增强等操作。我们可以使用一些常见的图像滤波方法，如高斯滤波器，来去除图像中的噪声。
2. **计算梯度：** 使用Sobel算子计算图像的梯度。通过对图像进行梯度计算，我们可以获得图像中的边缘强度和方向信息。
3. **非极大值抑制：** 对梯度幅值图像进行非极大值抑制，以细化边缘并保留局部最大值。这一步骤可以帮助我们定位图像中的细微边缘。
4. **双阈值处理：** 将梯度图像分为强边缘和弱边缘两部分。通过设定合适的阈值，将梯度幅值划分为高阈值和低阈值两个范围。强边缘被确定为可靠的边缘，而弱边缘则需要进一步的处理。
5. **边缘连接：** 对弱边缘进行边缘连接，以找到完整的边缘。通常使用一些连接策略，如基于像素连接或基于区域连接的方法，将弱边缘与强边缘连接起来，形成完整的边缘线。

下面介绍我们对Canny算法各步骤的具体实现:

### 1. 图像预处理

使用一个5x5的高斯滤波器对输入图像进行平滑处理，以减少明显噪声的影响。注：为了卷积能覆盖每一个像素，图像的边缘被以“反射”的形式补偿了两个像素，后面也有类似的操作。

> 图像变得“模糊”。

```python
def gaussian_blur(img):
    # 5x5 kernel
    gauss_mask = (
        np.array(
            [
                [2, 4, 5, 4, 2],
                [4, 9, 12, 9, 4],
                [5, 12, 15, 12, 5],
                [4, 9, 12, 9, 4],
                [2, 4, 5, 4, 2],
            ]
        )
        / 159
    )

    # Since the kernel is 2 more than the image, we pad the image with 2 using reflection
    padded = np.pad(img, 2, mode="reflect")

    out = convolve2d(padded, gauss_mask, mode="valid")

    return out
```

### 2. 计算梯度

使用Sobel算子计算图像在水平和垂直方向上的梯度。通过对图像进行卷积操作，我们可以获得每个像素点的梯度幅值和方向信息。其中幅值有**平方和开方法**和**绝对值法**，前者精度更高效率低，后者相反。一般默认使用绝对值法。具体公式如下：
$$
\begin{align}
   
   G &= \sqrt{G_x^2 + G_y^2} \\
   G &= |G_x| + |G_y| \\
   \theta &= \arctan{\frac{G_y}{G_x}}
   
   \end{align}
$$

> 利用Sobel算子获得图像的梯度，计算其幅值与方向。

```python
def sobel(img, l2gradient=False):
    # Sobel operator in x direction
    sobel_x = np.array(
        [
            [1, 0, -1],
            [2, 0, -2],
            [1, 0, -1],
        ]
    )

    # Sobel operator in y direction
    sobel_y = np.array(
        [
            [1, 2, 1],
            [0, 0, 0],
            [-1, -2, -1],
        ]
    )

    # Pad the image with 1
    padded = np.pad(img, 1, mode="reflect")

    # Convolve the image with the sobel operators
    dx = convolve2d(padded, sobel_x, mode="valid")
    dy = convolve2d(padded, sobel_y, mode="valid")

    # Compute the magnitude of the gradient
    if l2gradient:
        gradient_magnitude = np.sqrt(dx**2 + dy**2)
    else:
        gradient_magnitude = np.abs(dx) + np.abs(dy)

    # Compute the direction of the gradient
    gradient_direction = np.arctan2(dy, dx)

    # Normalize the magnitude of the gradient to 255
    gradient_magnitude = gradient_magnitude / np.max(gradient_magnitude) * 255

    return gradient_magnitude, gradient_direction
```

### 3. 非极大值抑制

对计算得到的梯度图像进行非极大值抑制。此步骤旨在保留具有局部最大梯度值的像素，以细化边缘。本质上，这一步骤是要找到每一个像素在其梯度方向上的两个“相邻”的像素，以判断该像素是否为局部最大值。本文实现了两种方法，下面分别介绍。

> 获得细边缘，默认采用线性插值的估计以提升效果。

函数`non_max_suppresion`实现了一种朴素的非极大值抑制，将每个像素梯度的方向“归纳”到距离最近的45度角内。共有0度，45度，90度，135度，180度五个方向。对于每种方向，对比不同位置的像素。例如当一个像素梯度指向45度方向时，它将于其“右上方”和“左下方”的像素进行比较。其他方向同理。

```python
def non_max_suppresion(m, d):
    """
    m: gradient magnitude, d: gradient direction
    this function rounds the gradient direction to the nearest 45 degrees
    and checks if the pixel is a local maximum in the direction of the gradient
    """
    deg = np.rad2deg(d)
    deg[deg < 0] += 180
    deg = np.round(deg / 45) * 45

    # Create a new image of zeros with the same shape as the original image
    new_image = np.zeros_like(m)

    count = 0

    h, w = m.shape
    # Iterate over the image pixels
    for i in range(1, h - 1):
        for j in range(1, w - 1):
            direction = deg[i, j]

            if direction == 0 or direction == 180:
                is_max = m[i, j] >= m[i, j - 1] and m[i, j] >= m[i, j + 1]
            elif direction == 45:
                is_max = m[i, j] >= m[i - 1, j + 1] and m[i, j] >= m[i + 1, j - 1]
            elif direction == 90:
                is_max = m[i, j] >= m[i - 1, j] and m[i, j] >= m[i + 1, j]
            elif direction == 135:
                is_max = m[i, j] >= m[i - 1, j - 1] and m[i, j] >= m[i + 1, j + 1]

            # Count the pixels that are being pruned
            count += is_max

            # Set the pixel to 0 if it is not a maximum
            new_image[i, j] = m[i, j] * is_max

    print("Pixels pruned by non-maximum suppression:", count)

    return new_image
```

函数`non_max_suppresion_with_interpolation`则尝试了一种更加精确的方法，其精确度的提升在于不再将梯度方向粗略地“归纳”为45度角，而是采用了线性插值估计的方法。原理如下：梯度方向落入每个45度区域有两个方向可供“选择”。前文提到的朴素方法直接选择距离最近的45度方向。新方法则线性地估计两种方向的权重，并据此加权地计算出其“相邻”像素的幅值。以梯度方向在(0,45]范围上举例，当梯度方向更接近0度的时候显然“正右方”的像素权重应该更大，相反地“右上方”的像素权重应该更小。

```python
def non_max_suppresion_with_interpolation(m, d):
    """
    m: gradient magnitude, d: gradient direction
    this function uses linear interpolation to check if the pixel is a local maximum
    in the direction of the gradient
    """
    deg = np.copy(d)
    deg[deg < 0] += np.pi

    new_image = np.zeros_like(m)

    count = 0

    h, w = m.shape
    for i in range(1, h - 1):
        for j in range(1, w - 1):
            direction = deg[i, j]

            # if direction equals 0
            if direction == 0:
                is_max = m[i, j] >= m[i, j - 1] and m[i, j] >= m[i, j + 1]

            # if direction belongs to (0, 45]
            elif 0 < direction <= np.pi / 4:
                r = direction
                x = (1 - np.tan(r)) * m[i, j + 1] + np.tan(r) * m[i - 1, j + 1]
                y = (1 - np.tan(r)) * m[i, j - 1] + np.tan(r) * m[i + 1, j - 1]
                is_max = m[i, j] >= x and m[i, j] >= y

            # if direction belongs to (45, 90)
            elif np.pi / 4 < direction < np.pi / 2:
                r = np.pi / 2 - direction
                x = (1 - np.tan(r)) * m[i - 1, j] + np.tan(r) * m[i - 1, j + 1]
                y = (1 - np.tan(r)) * m[i + 1, j] + np.tan(r) * m[i + 1, j - 1]
                is_max = m[i, j] >= x and m[i, j] >= y

            # if direction equals 90
            elif direction == np.pi / 2:
                is_max = m[i, j] >= m[i - 1, j] and m[i, j] >= m[i + 1, j]

            # if direction belongs to (90, 135)
            elif np.pi / 2 < direction < 3 * np.pi / 4:
                r = direction - np.pi / 2
                x = (1 - np.tan(r)) * m[i - 1, j] + np.tan(r) * m[i - 1, j - 1]
                y = (1 - np.tan(r)) * m[i + 1, j] + np.tan(r) * m[i + 1, j + 1]
                is_max = m[i, j] >= x and m[i, j] >= y

            # if direction belongs to [135, 180)
            elif 3 * np.pi / 4 <= direction < np.pi:
                r = np.pi - direction
                x = (1 - np.tan(r)) * m[i, j - 1] + np.tan(r) * m[i - 1, j - 1]
                y = (1 - np.tan(r)) * m[i, j + 1] + np.tan(r) * m[i + 1, j + 1]
                is_max = m[i, j] >= x and m[i, j] >= y

            # if direction equals 180
            elif direction == np.pi:
                is_max = m[i, j] >= m[i, j - 1] and m[i, j] >= m[i, j + 1]

            # Count the pixels that are being pruned
            count += is_max

            new_image[i, j] = m[i, j] * is_max

    print("Pixels pruned by non-maximum suppression:", count)

    return new_image
```

### 4. 双阈值处理

对抑制后的梯度图像进行阈值处理。根据预先设定的高阈值和低阈值，按照梯度幅值像素被分为两类：梯度幅值大于等于高阈值被认为是强边缘，大于等于低阈值且小于高阈值被认为是弱边缘。小于低阈值的像素则被忽略。

> 将像素分为强弱两类，剔除以外的像素。

```python
def double_threshold(m, low_threshold, high_threshold):
    strong_edges = np.zeros_like(m)
    weak_edges = np.zeros_like(m)

    # Get the strong edges
    strong_edges[m >= high_threshold] = 1

    # Get the weak edges
    weak_edges[np.logical_and(m >= low_threshold, m < high_threshold)] = 1

    return strong_edges, weak_edges
```

### 5. 边缘连接

对弱边缘进行边缘连接操作，以找到完整的边缘。该步骤采用基于像素连接的方法，将弱边缘与其相邻的强边缘像素连接起来，形成连续的边缘线。具体原理为：通过观察一个弱边缘像素和它的8个连接的邻域像素，只要其中有一个强边缘像素，这个弱边缘点就可以被确定为应该被保留的一个。这些弱边缘像素将成为强边缘，然后可以使其邻近的弱边缘像素递归地被保留下来。

> 保留与强边缘相连的弱边缘。

```python
   def hysteresis(weak, strong):
       while True:
           # Get the indices of the weak edges
           indices = np.argwhere(weak > 0)
           found = False
           # Iterate over the weak edges
           for i, j in indices:
               neighborhood = strong[i - 1 : i + 2, j - 1 : j + 2]
               if np.any(neighborhood > 0):
                   found = True
                   # Set the weak edge to a strong edge
                   weak[i, j] = 0
                   strong[i, j] = 1
   
           # If there are no new strong edges, we are done
           if not found:
               break
   
       strong[strong > 0] = 255
   
       return strong
```

### 6. Canny算法

将上述五个步骤组合在一起便得到了Canny边缘检测算法的一种实现。该函数输入为图像、低阈值、高阈值，输出为图像边缘的二值图像。代码如下：

```python
def canny(image, low_threshold, high_threshold):
    print("low_threshold:", low_threshold, "high_threshold:", high_threshold)

    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blur = gaussian_blur(image)
    m, d = sobel(blur)
    m = non_max_suppresion_with_interpolation(m, d)
    strong, weak = double_threshold(m, low_threshold, high_threshold)
    strong = hysteresis(weak, strong)

    # return as uint8
    return strong.astype(np.uint8)
```

## Canny算法测试

对于Canny边缘检测算法的阈值，经验上通常设置低阈值为高阈值的1/3~1/2。对经典的**莱娜图**进行边缘检测，遍历0到255为高阈值。

测试代码如下：

```python
import my_canny as my
import cv2

image = cv2.imread("images/lena.png")

# iterate over the thresholds
# low_threshold is 1/2 of high_threshold
for i in range(1, 256):
    canny_image = my.canny(image, i / 2, i)
    cv2.imwrite("images/lena/2x/{:03d}.png".format(i), canny_image)

# iterate over the thresholds
# low_threshold is 1/3 of high_threshold
for i in range(1, 256):
    canny_image = my.canny(image, i / 3, i)
    cv2.imwrite("images/lena/3x/{:03d}.png".format(i), canny_image)
```

当低阈值为高阈值的1/2，效果如下：

（从左到右分别是：高阈值20，高阈值40，高阈值60，高阈值80）

| <img src="/home/arcohol/projects/opencv-toy/images/lena/2x/020.png" alt="020" style="zoom:50%;" /> | <img src="/home/arcohol/projects/opencv-toy/images/lena/2x/040.png" alt="040" style="zoom:50%;" /> | <img src="/home/arcohol/projects/opencv-toy/images/lena/2x/060.png" alt="060" style="zoom:50%;" /> | <img src="/home/arcohol/projects/opencv-toy/images/lena/2x/080.png" alt="080" style="zoom:50%;" /> |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |

当低阈值为高阈值的1/3，效果如下：

（从左到右分别是：高阈值20，高阈值40，高阈值60，高阈值80）

| <img src="/home/arcohol/projects/opencv-toy/images/lena/3x/020.png" alt="020" style="zoom:50%;" /> | <img src="/home/arcohol/projects/opencv-toy/images/lena/3x/040.png" alt="040" style="zoom:50%;" /> | <img src="/home/arcohol/projects/opencv-toy/images/lena/3x/060.png" alt="060" style="zoom:50%;" /> | <img src="/home/arcohol/projects/opencv-toy/images/lena/3x/080.png" alt="080" style="zoom:50%;" /> |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |

### 小结

阈值比例对输出结果影响不大，仅有极其细微的差别，即相同高阈值检测结果几乎一样。

随着高阈值的增大，边缘越来越稀疏。这是符合直觉的。

注：对于各种各样的图像，很难找到一个通用的“合适的”阈值。因此在车牌识别上具有一定的局限性。

## Canny算法在车牌识别领域中的应用

在获取边缘图像后，膨胀和腐蚀操作常被用于车牌检测中的后续处理步骤。以下是简要的步骤说明：

1. 边缘检测：首先，使用边缘检测算法（如Canny边缘检测）获得输入图像的边缘图像。这会突出图像中的边缘部分。
2. 膨胀操作：膨胀操作是一种形态学操作，用于扩展边缘图像中的边缘区域。它通过在图像中移动一个结构元素（例如矩形或椭圆）来增加边缘的宽度和大小。这有助于将分散的边缘区域连接成连续的轮廓，使车牌区域更加完整。
3. 腐蚀操作：腐蚀操作是形态学操作的另一种类型，用于缩小边缘图像中的边缘区域。它通过在图像中移动结构元素来减小边缘的宽度和大小。腐蚀操作有助于去除细小的边缘间隙，使车牌区域更加紧凑。
4. 组合操作：通常，膨胀和腐蚀操作结合在一起使用，以产生更好的结果。一种常见的组合方式是先进行膨胀操作，然后再进行腐蚀操作，这被称为闭运算。闭运算可以填充较小的空洞和连接断开的边缘区域，以更好地定义车牌的形状。
5. 车牌检测：在膨胀和腐蚀操作之后，可以应用其他技术（如连通组件分析、形状特征等）来检测和定位车牌区域。这可以包括查找具有特定宽高比例、颜色特征或字符布局的区域，以确定最可能的车牌候选区域。

需要注意的是，膨胀和腐蚀操作的具体参数（如结构元素的形状和大小）需要根据实际情况进行调整和优化，以获得最佳的车牌检测效果。此外，车牌检测是一个复杂的任务，可能需要结合其他图像处理和模式识别技术来提高准确性和鲁棒性。

下面展示用简单的膨胀与腐蚀操作检测车牌区域，代码如下：

> 使用Canny边缘检测算法`my_canny`对输入图像`sample`进行边缘检测。
>
> 使用膨胀（`dilate`）和腐蚀（`erode`）操作对边缘图像进行形态学处理。这一系列的形态学操作旨在填充边缘、连接断开的边缘区域，并且强调车牌的形状特征。
>
> 使用OpenCV中的`findContours`函数检测模糊处理后的图像`blur`中的轮廓。轮廓是图像中连续的边缘曲线。注：轮廓检测不在本文的讨论范围内。
>
> 遍历检测到的轮廓，并使用矩形框标记符合特定宽高比范围的轮廓。在输入图像上绘制矩形框以标记车牌区域。

```python
    edges = my_canny.canny(sample, 50, 100)

    element_x = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 3))
    element_y = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 20))

    # Perform morphological operations
    img1 = cv2.dilate(edges, element_x, iterations=2)
    img2 = cv2.erode(img1, element_x, iterations=6)
    img3 = cv2.dilate(img2, element_x, iterations=4)
    img4 = cv2.erode(img3, element_y, iterations=2)
    img5 = cv2.dilate(img4, element_y, iterations=3)

    blur = cv2.medianBlur(img5, 15)

    # Find contours
    contours, hierarchy = cv2.findContours(blur, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    for c in contours:
        x, y, w, h = cv2.boundingRect(c)
        r = w / h
        if 2 < r < 5:
            cv2.rectangle(sample, (x, y), (x + w, y + h), (0, 255, 0), 2)
```

### 效果展示

对于简单场景，Canny算法配合膨胀腐蚀操作可以很好的检测出车牌区域。

效果如下：

<img src="/home/arcohol/projects/opencv-toy/out-1.png" alt="out-1" style="zoom:50%;" />

<img src="/home/arcohol/projects/opencv-toy/out-2.png" alt="out-2" style="zoom:50%;" />

<img src="/home/arcohol/projects/opencv-toy/out-3.png" alt="out-3" style="zoom:50%;" />

<img src="/home/arcohol/projects/opencv-toy/out-4.png" alt="out-4" style="zoom:50%;" />

![out-5](/home/arcohol/projects/opencv-toy/out-5.png)

![out-6](/home/arcohol/projects/opencv-toy/out-6.png)

## 软件配置

算法均使用python实现，演示/调试则使用jupyter notebook

算法依赖见目录下`requirements.txt`

各依赖用途如下：

- numpy（对图像信息进行操作）
- opencv_python（读取、写入图像，膨胀与腐蚀，轮廓检测）
- scipy（卷积操作）

